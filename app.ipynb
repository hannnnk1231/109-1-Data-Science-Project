{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from yolov4.tf import YOLOv4\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildActionDict():\n",
    "    with open(\"ava_videos/action_list.pbtxt\", 'r') as file:\n",
    "        actions = file.read()\n",
    "    actions = actions.split('item {\\n  ')[1:]\n",
    "    actions = [[keys.split(': ') for keys in ac.split('\\n')[:2]] for ac in actions]\n",
    "    actions_dict ={}\n",
    "    for ac in actions:\n",
    "        actions_dict[int(ac[1][1])] = ac[0][1][1:-1]\n",
    "    return actions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGroundTruthBbox(df):\n",
    "    bboxes = []\n",
    "    for idx, row in df.iterrows():\n",
    "        bboxes.append([row['x1'], row['y1'], row['x2'], row['y2'], row['action_id']])\n",
    "    return np.array(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_groundTruth_bboxes(image, bboxes):\n",
    "    image = np.copy(image)\n",
    "    height, width, _ = image.shape\n",
    "    bboxes[:, [0, 2]] = bboxes[:, [0, 2]] * width\n",
    "    bboxes[:, [1, 3]] = bboxes[:, [1, 3]] * height\n",
    "    actions = buildActionDict()\n",
    "    for bbox in bboxes:\n",
    "        top_left = (int(bbox[0]), int(bbox[1]))\n",
    "        bottom_right = (int(bbox[2]), int(bbox[3]))\n",
    "        action_id = bbox[4]\n",
    "        bbox_color = (255, 0, 255)\n",
    "        font_size = 0.4\n",
    "        font_thickness = 1\n",
    "        cv2.rectangle(image, top_left, bottom_right, bbox_color, 2)\n",
    "        bbox_text = actions[action_id]\n",
    "        t_size = cv2.getTextSize(bbox_text, 0, font_size, font_thickness)[0]\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            top_left,\n",
    "            (top_left[0] + t_size[0], top_left[1] - t_size[1] - 3),\n",
    "            bbox_color,\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            bbox_text,\n",
    "            (top_left[0], top_left[1] - 2),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            font_size,\n",
    "            (255 - bbox_color[0], 255 - bbox_color[1], 255 - bbox_color[2]),\n",
    "            font_thickness,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_objects(image, bboxes, classes):\n",
    "    image = np.copy(image)\n",
    "    height, width, _ = image.shape\n",
    "    bboxes.view('i8,i8,i8,i8,i8,i8').sort(order=['f0','f1'], axis=0)\n",
    "    bboxes[:, [0, 2]] = bboxes[:, [0, 2]] * width\n",
    "    bboxes[:, [1, 3]] = bboxes[:, [1, 3]] * height\n",
    "    person_count = 0\n",
    "    for bbox in bboxes:\n",
    "        c_x = int(bbox[0])\n",
    "        c_y = int(bbox[1])\n",
    "        half_w = int(bbox[2] / 2)\n",
    "        half_h = int(bbox[3] / 2)\n",
    "        top_left = [c_x - half_w, c_y - half_h]\n",
    "        bottom_right = [c_x + half_w, c_y + half_h]\n",
    "        top_left[0] = max(top_left[0], 0)\n",
    "        top_left[1] = max(top_left[1], 0)\n",
    "        bottom_right[0] = min(bottom_right[0], width)\n",
    "        bottom_right[1] = min(bottom_right[1], height)\n",
    "        class_id = int(bbox[4])\n",
    "        if class_id == 0:\n",
    "            person_count += 1\n",
    "            windowName = \"{}_{}\".format(classes[class_id],person_count)\n",
    "            cv2.namedWindow(windowName, cv2.WINDOW_AUTOSIZE)\n",
    "            obj = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0], :]\n",
    "            cv2.imshow(windowName, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildYoloModel():\n",
    "    yolo = YOLOv4()\n",
    "    yolo.classes = \"coco.names\"\n",
    "    yolo.input_size=(608,608)\n",
    "    yolo.make_model()\n",
    "    yolo.load_weights(\"yolov4.weights\", weights_type='yolo')\n",
    "    return yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(media_path, yolo, groundTruth_df, iou_threshold = 0.3, score_threshold = 0.4, start_time = 902, end_time = 1798):\n",
    "    \n",
    "    if not os.path.exists(media_path):\n",
    "        raise FileNotFoundError(\"{} does not exist\".format(media_path))\n",
    "\n",
    "    cv2.namedWindow(\"result\", cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.namedWindow(\"origin\", cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.namedWindow(\"ground_truth\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    cap = cv2.VideoCapture(media_path)\n",
    "\n",
    "    if cap.isOpened():\n",
    "        while True:\n",
    "            try:\n",
    "                is_success, frame = cap.read()\n",
    "            except cv2.error:\n",
    "                continue\n",
    "                \n",
    "            now_second = cap.get(0)/1000\n",
    "            \n",
    "            if now_second < start_time: continue\n",
    "            if (not is_success) or (now_second >= end_time+1): break\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            bboxes = yolo.predict(\n",
    "                frame,\n",
    "                iou_threshold=iou_threshold,\n",
    "                score_threshold=score_threshold,\n",
    "            )\n",
    "            \n",
    "            groundTruth_bboxes = getGroundTruthBbox(groundTruth_df[groundTruth_df['timestamp']==int(now_second)])\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            image = yolo.draw_bboxes(frame, bboxes)\n",
    "            groundTruth_img = draw_groundTruth_bboxes(frame, groundTruth_bboxes)\n",
    "\n",
    "            cv2.imshow(\"result\", image)\n",
    "            cv2.imshow(\"origin\", frame)\n",
    "            cv2.imshow(\"ground_truth\", groundTruth_img)\n",
    "            #draw_objects(frame, bboxes, yolo.classes)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ava_videos/ava_file_names_trainval_v2.1.txt', 'r') as f:\n",
    "    video_names = f.readlines()\n",
    "video_names = [v.rstrip().split('.') for v in video_names]\n",
    "video_names_dict = {}\n",
    "for video in video_names:\n",
    "    video_names_dict[video[0]] = video[0]+'.'+video[1]\n",
    "\n",
    "columns = ['video_id', 'timestamp', 'x1', 'y1', 'x2', 'y2', 'action_id', 'person_id']\n",
    "train_df = pd.read_csv('ava_videos/ava_train_v2.2.csv')\n",
    "val_df = pd.read_csv('ava_videos/ava_val_v2.2.csv')\n",
    "train_df.columns = columns\n",
    "val_df.columns = columns\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "train_df.drop(train_df[train_df['video_id']=='#NAME?'].index, inplace=True)\n",
    "train_df['video_id'] = train_df['video_id'].map(video_names_dict)\n",
    "val_df['video_id'] = val_df['video_id'].map(video_names_dict)\n",
    "\n",
    "train_videos = train_df['video_id'].unique()\n",
    "val_videos = val_df['video_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = buildYoloModel()\n",
    "train_path = \"ava_videos/train/\"\n",
    "val_path = \"ava_videos/val/\"\n",
    "media_name = train_videos[20]\n",
    "media_path = train_path + media_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run(media_path, yolo, train_df[train_df['video_id']==media_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
